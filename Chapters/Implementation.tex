\chapter{Implementation}
\label{ch:implementation}

This chapter details the implementation of the compiler, with the first few sections covering all
major phases from parsing to LLVM IR generation. Where appropriate, examples of how the language is
represented at each stage of the compilation process will be provided. The final sections of this
chapter will specifically cover the implementation and handling of structs, closures and
higher-order functions, as these language features first require the full understanding of the
implementation in order to be explained effectively.

\section{Parsing}

As the library used for parsing, \emph{FastParse}, is a parser combinator library, the parser is
able to closely reflect the formal grammer designed, with each non-terminal symbol being implemented
as a function that returns a parser. The parser output is mapped to an abstract syntax tree (AST),
represented by Scala case classes.

A condensed example can be seen as follows:

\begin{code}{scala}
    sealed trait Exp
    case class Call(name: String, args: Seq[Exp]) extends Exp
    case class Num(i: Int) extends Exp
    case class Bool(b: Boolean) extends Exp
    case class Var(s: String) extends Exp

    def NumParser[$: P] =
        P(CharsWhileIn("0-9", 1)).!.map(_.toInt)

    def BoolParser[$: P] =
        P("true").map(_ => true) |
        P("false").map(_ => false)

    def IdParser[$: P] = P(
        !StringIn("if", "then", "else", "print", "def", "val", "enum", "struct", "true", "false")
        ~ CharIn("A-Za-z_") ~~ CharsWhileIn("A-Za-z0-9_", 0)
    ).!

    def Primary[$: P]: P[Exp] = P(
        (IdParser ~ "(" ~ Exp.rep(0, ",") ~ ")").map(Call) |
        NumParser.map(Num) |
        BoolParser.map(Bool) |
        IdParser.map(Var)
    )
\end{code}

\noindent where \texttt{IdParser}, \texttt{NumParser} and \texttt{BoolParser} define the lexical
structure of identifiers, numbers and booleans respectively. This parser allows for the following
transformation between the input and the AST:

\begin{tcolorbox}
    \begin{minted}{scala}
        // input
        foo(6 + bar(4), 2)
    \end{minted}
    \tcblower
    \begin{minted}{scala}
        // AST
        Call("foo", Seq(
            Op(
                Num(6),
                "+",
                Call("bar", Seq(Num(4)))
            ),
            Num(2)
        ))
    \end{minted}
\end{tcolorbox}

A particular implementation detail of the parser is in handling operator precedence. A common
grammar for parsing with operator precedence, notated in Extended Backus-Naur Form (EBNF), is as
follows:

\begin{center}
    \begin{grammar}
        <expr> ::= <term>
        \alt <expr> `+' <term>
        \alt <expr> `-' <term>

        <term> ::= <factor>
        \alt <term> `*' <factor>
        \alt <term> `/' <factor>

        <factor> ::= <number>
        \alt `(' <expr> `)'
    \end{grammar}
\end{center}

While this correctly handles operator precedence, it does not handle left-associativity of
operators if implemented naively. For example, the grammar above would parse
\(1 - 2 - 3 ~[= -4]\) as \(1 - (2 - 3) ~[=2]\),
which is not the desired behaviour. To handle this, the grammar must be modified to include
left-associative rules:

\begin{grammar}
    <expr> ::= <term> \{ (`+' | `-') <term> \}

    <term> ::= <factor> \{ (`*' | `/') <factor> \}

    <factor> ::= <number>
    \alt `(' <expr> `)'
\end{grammar}

Using the semantic actions of parser combinators, a left-associative transformation can be
applied to the parsed output. This is achieved by defining a recursive function that takes the
parsed output and applies the left-associative transformation. The implementation of this using
\emph{FastParse} is as follows:

\begin{code}{scala}
    def lft(a: Exp, b: Seq[(String, Exp)]): Exp = (a, b) match {
        case (`a`, (b, c) :: next) => lft(Op(a, b, c), next)
        case _ => a
    }

    def Expr[$: P]: P[Exp] =
        (Term ~ (CharIn("+\\-").! ~ Term).rep).map(lft(_,_))

    def Term[$: P]: P[Exp] =
        (Factor ~ (CharIn("/*%").! ~ Factor).rep).map(lft(_,_))

    def Factor[$: P]: P[Exp] =
        NumParser.map(Num) |
        "(" ~ Expr ~ ")"
    ...
\end{code}

To parse the source file as a whole, the file is converted into a String, and passed to the parser
via the \mintinline{scala}{fastparse.parse(string, parser)} function. If the parser is successful,
the AST is returned, otherwise an error message is printed. As mentioned in
Chapter~\ref{ch:design}, care was taken to ensure the grammar created was unambiguous and not
left-recursive. The final language grammar specification is available in Appendix~\ref{app:grammar}.

\section{IR Generation}

After generating the AST from the parser, it is converted to the ANF IR as a series of
let-expressions, defining the scope of variables and their values. This can be seen as equivalent to
lambda abstractions in the lambda calculus, with the variable bindings representing the arguments to
the lambda, and the body of the let-expression representing the body of the lambda. The conversion
is performed via a Continuation-Passing Style function. Consider the following program and it's
ANF-style intermediate data representation:

\begin{tcolorbox}
    \begin{minted}{scala}
        // Program
        foo(6 + bar(4), 2)
    \end{minted}
    \tcblower
    \begin{minted}{scala}
        // ANF IR
        Let("tmp0", Call("bar", [Num(4)]),
            Let("tmp1", Op(Num(6), "+", Var("tmp0")),
                Let("tmp2", Call("foo", [Var("tmp1"), Num(2)])
                    Return(Var("tmp2"))
                )
            )
        )
    \end{minted}
\end{tcolorbox}

Observe that the deeper expressions appear before shallower ones in the ANF
representation. A simple recursive solution for converting the program to ANF would not work as this
structure cannot be created bottom-up. It can be seen that the later expressions of the IR depend on
the expressions constructed earlier on, such as \texttt{tmp2} depending on \texttt{tmp1}, which in
turn depends on \texttt{tmp0}.

To solve this `inversion' of calculating values, CPS allows for passing a continuation function
representing the context in which a value is used. This allows for the expression to remain
incomplete until the value it depends on is assigned to a variable.

The IR generation function as implemented takes an AST expression and a continuation function, that
takes a value and returns an ANF expression. The CPS function itself then returns the full program
under an ANF expression. A simplified version of the CPS function is as follows:

\begin{code}{Scala}
    def CPS(e: Exp)(k: KVal => KAnf) : KAnf = e match {
        // Values are passed to the continuation function
        case Var(s) => k(KVar(s))
        case Num(i) => k(KNum(i))
        case Bool(b) => k(KBool(b))
        case Flt(f) => k(KFloat(f))
        ...
        // Other expressions are handled by creating a new continuation function
        case Op(e1, o, e2) => {
            val z = counter.Fresh("tmp")
            CPS(e1)((y1) =>
                CPS(e2)((y2) =>
                    KLet(z, Kop(o, y1, y2), k(KVar(z)))
                )
            )
        }
        case Func(name, args, body) =>
            KFun(name, args, CPS(body)((y) => KReturn(y)), k(KVar(name)))
        case StructDef(name, items) =>
            KStructDef(Struct(name, items), k(KVar(name)))
        ...
    }
\end{code}

The \texttt{Fresh} function is used to generate a globally unique name for each temporary variable
introduced, in order to fulfil the SSA requirements that LLVM IR has.

For a cleaner function interface (and to hide the implementation detail of the continuation), the
CPS function is wrapped in a higher-order function that takes the AST expression, which calls the
CPS function with the AST and a continuation that binds the final result to a return statement.

\subsection{Handling typing}

As the LLVM IR is statically typed, the ANF IR to be generated must also be typed. While more
complex type systems exist, such as Hindley-Milner type inference, the type system used in this
project heavily leans on the existing type system of LLVM IR, with the programmer being required to
declare the types of variables alongside their definitions. This is done by adding type hints to
variable definitions, function arguments and return types.

If the type hint specified by the programmer is outside the set of pre-defined types in the language
(e.g. \texttt{Int}, \texttt{Float}, etc.), the type is marked in the parser as a user-defined type
until after the ANF IR generation process, where the type is resolved to a concrete type (e.g. a
struct).

These types are then propagated through the ANF IR generation process via a type environment, which
is a map from variable names to their types. The type environment is updated as new variables are
bound to typed values, and the types of expressions are checked against the type environment. As the
type environment is recursively passed through the function, the scope of the type environment will
naturally reflect available types at any given point in the program. Using the example from earlier,
an updated version of the CPS function that includes type propagation is as follows:

\begin{code}{scala}
    type TypeEnv = Map[String, Type]

    def CPS(e: Exp, ty: TypeEnv)(k: (KVal, TypeEnv) => KAnf) : KAnf = e match {
        // Values and their types are passed to the continuation function
        case Var(s) => k(KVar(s, ty(s)), ty)
        case Num(i) => k(KNum(i), ty)
        case Bool(b) => k(KBool(b), ty)
        case Flt(f) => k(KFloat(f), ty)
        ...
        // Other expressions are handled by creating a new continuation function
        case Op(e1, o, e2) => {
            val z = counter.Fresh("tmp")
            CPS(e1, ty)((y1, t1) =>
                CPS(e2, t1)((y2, t2) =>
                    KLet(z, Kop(o, y1, y2), k(KVar(z, y1.get_type), t2))
                )
            )
        }
        case Func(name, args, ret, body) => {
            // update the type environment for the function body
            val body_ty = ty
                ++ args.map{case (x, t) => (x, t)}
                + (name -> FnType(args.map(_._2).toList, ret))
            // update the type environment for after the function itself
            val return_ty = ty
                + (name -> FnType(args.map(_._2).toList, ret))
            KFun(name, args, ret, CPS(body, body_ty)((y, _) => KReturn(y)), k(KVar(name), return_ty))
        }
        case StructDef(name, items) =>
            // update the ty with struct type, as well as items inside the struct
            val updated_ty = ty
                + (name -> UserType(name))
                ++ items.map{case (x, t) => (s"$name.$x", t)}
            KStructDef(Struct(name, items), k(KVar(name), updated_ty))
        ...
    }
\end{code}



\section{Enumerated Types and Pattern Matching}

The implementation of enums and pattern matching requires the consideration of two main aspects:
\begin{enumerate}
    \singlespacing
    \item The definition of enums and their values.
    \item Referencing enums in comparisons and pattern matching expressions.
\end{enumerate}
Consider the following program containing an enum definition and a pattern matching expression:

\begin{tcolorbox}
    \begin{minted}{scala}
        enum Days = Spring | Summer | Autumn | Winter;

        def main() = {
            val contrivedExample: Season = Season::Spring;
            print(contrivedExample match {
                case Season::Spring => true
                case Season::Autumn => true
                case _ => false
            });
            0
        }
        // Output: true
    \end{minted}
    \tcblower
    \footnotesize
    An example program that demonstrates the use of enums and pattern matching.
    This example will be used throughout this section to illustrate the changes required.
\end{tcolorbox}

The LLVM IR does not have a native representation of enums, nor does it have native control flow
instructions for pattern matching. To accommodate these language features, a pre- and
post-processing step is introduced to the ANF IR generation.

The pre-processing step is responsible for extracting all enum definitions from the AST, collecting
them into a map from enum names to their possible values, and transforming match expressions into a
series of if-else expressions. This step is done prior to the ANF IR generation as it eliminates the
need to handle the pattern matching transformation within the ANF IR generation itself. Using the
example above, the pre-processing step would transform the program into:

\begin{tcolorbox}
    \begin{minted}{scala}
    def main() = {
        val contrivedExample: Season = Season::Spring;
        print(
            if (contrivedExample == Season::Spring) {
                true
            } else if (contrivedExample == Season::Autumn) {
                true
            } else {
                false
            }
        );
        0
    }
    \end{minted}
    \tcblower
    \footnotesize
    For illustration purposes, this code is a representation of the changes that would be made to
    the AST.
\end{tcolorbox}

This step is implemented as a series of recursive functions that traverse the AST and transform the
program accordingly. Where a default catch-all case is provided in the match expression, the
transformation is straightforward, as the default case can be directly translated to an else
statement, with the remaining cases following it ignored. Note that for the match expression, a
`no-op' instruction is added to the end of the if-else chain to ensure that the match expression
returns a value. This is necessary in the event where no default (else) case is provided. The no-op
instruction is eliminated by the LLVM IR optimiser during compilation, leaving the semantics of the
program intact.

\begin{code}{scala}
    // Removes Enum definitions from the AST and returns them separately
    def extract_enums(e: Exp) : (Map[String, Type], Exp) = e match {
        case Sequence(e1: EnumDef, e2) =>
            val (enums, e_) = extract_enums(e2)
            (enums + (e1.name -> EnumType(e1.vals)), e_)
        // ... Other recursive cases ...
        case e: EnumDef => (Map(e.name -> EnumType(e.vals)), e)
        case e => (Map(), e)
    }

    // Convert match statements to if-else statements
    def transform_match_to_if(e: Exp) : Exp = e match {
        case Match(a, cases) =>
            // Fold start value is a no-op (0 + 0) if no default case is given
            cases.foldRight[Exp](Op(Num(0), "+", Num(0)))((mcase, acc) => {
                val MCase(root, item, exp) = mcase
                if root == "" && item == "_" then
                    transform_match_to_if(exp)    // default
                else
                    If(Op(Var(a), "==", EnumRef(root, item)), transform_match_to_if(exp), Some(acc))
            })
        // ... Other recursive cases ...
        case e => e
    }
\end{code}

The post-processing step is responsible for replacing enum references with their corresponding
integer values, using the map generated in the pre-processing step. The integer value assigned to
each enum value is determined by the index in which they are defined in the enum definition,
identical to the behaviour of C and C++ enums. This step is done after the ANF IR generation to
allow for the specific enum types to be properly propagated through the ANF IR\@. The
post-processing step would transform the program into:

\begin{tcolorbox}
    \begin{minted}{scala}
        def main() = {
            val contrivedExample: Int = 0;
            print(
                if (contrivedExample == 0) {
                    true
                } else if (contrivedExample == 2) {
                    true
                } else {
                    false
                }
            );
            0
        }
    \end{minted}
    \tcblower
    \footnotesize
    For illustration purposes, this code is a representation of the changes that would be made to
    the ANF IR.
\end{tcolorbox}

This step is also implemented as a series of recursive functions that traverse the ANF IR, with the
enum replacement carried out as a simple map lookup.

\begin{code}{scala}
    // ...
    case v: KEnum =>
        en_map.get(v.root) match {
            // check if enum is in map
            case Some(EnumType(items)) =>
                val idx = items.indexOf(v.item)
                // check if valid enum value
                if idx == -1 then
                    throw new Exception("Undefined enum value")
                KNum(idx)
            case _ => throw new Exception("Undefined enum type")
        }
    // ...
\end{code}

At this point, all references to enums have been removed, and the program is in a form that can
almost directly be translated to LLVM IR.

\section{LLVM IR Generation}

After both the ANF IR generation and post-processing steps, the state of the program is such that
the chain of let-expressions encompasses the entire program, with the final continuation function
being the return statement. This includes the definitions of functions, structs and closures, as
well as the main function itself. To extract certain constructs like function definitions from these
let-expressions, a recursive function is used to hoist them out and into the top-level of the
program. This is done to ensure that definitions are available globally, as they are in the source
language.

\begin{code}{scala}
    def hoist(e: KAnf): (List[CFunc], KAnf, List[Env], List[Struct]) = e match {
        case KFun(fnName, args, ret, body, next) => {
            val (fns, e, envs, structs) = hoist(body)
            val (fns2, e2, envs2, structs2) = hoist(next)
            val entry = counter.Fresh("entry")
            val fn = CFunc(fnName, args, ret, e)
            (fn :: fns ::: fns2, e2, envs ::: envs2, structs ::: structs2)
        }
        case KIf(x1, e1, e2) => {
            val (fns, t, envs, structs) = hoist(e1)
            val (fns2, f, envs2, structs2) = hoist(e2)
            val thn = counter.Fresh("then")
            val els = counter.Fresh("else")
            (fns ::: fns2, KIf(x1, t, f), envs ::: envs2, structs ::: structs2)
        }
        case KLetEnv(x, env: Env, next) => {
            val (fns, e1, envs, structs) = hoist(next)
            (fns, KLetEnv(x, env, e1), env :: envs, structs)
        }
        case KLet(x, v, next) => {
            val (fns, e1, envs, structs) = hoist(next)
            (fns, KLet(x, v, e1), envs, structs)
        }
        case KConst(x, v, e) => {
            val (fns, e1, envs, structs) = hoist(e)
            (fns, KConst(x, v, e1), envs, structs)
        }
        case KStructDef(struct, e) => {
            val (fns, e1, envs, structs) = hoist(e)
            (fns, KStructDef(struct, e1), envs, struct :: structs)
        }
        case _ => (Nil, e, Nil, Nil)
    }
\end{code}

The final step of the compilation process is the generation of LLVM IR from the ANF IR\@. A prelude
is added to the top of all programs, containing the necessary LLVM IR code to define runtime library
code, such as \texttt{print_*} functions. While limited in the scope of this project, the prelude
can be expanded to include more complex library functions, such as the implementation of language
features like strings. This could be achieved by writing the implementation in a higher-level
language like C, and then appending the emitted LLVM IR to the final executable.

The LLVM IR generation is done by recursively traversing the ANF IR, emitting the corresponding LLVM
IR for each construct. Certain constructs, such as arithmetic operations, are conditional on the
type of the values involved. For example, the LLVM IR for adding two integers is different from
adding two floating-point numbers.

Other constructs, such as floating point literals themselves, require special handling as they
cannot be emitted directly. The LLVM IR require floating point literals to be exact representations
of the floating point number, using the 64-bit IEEE-754 standard. This requires all (32-bit) floats
to first be extended to (64-bit) doubles, before being converted to their hexadecimal
representation.

The LLVM IR is then written to a file, which can be in turn be compiled using the LLVM toolchain, or
ran using an LLVM interpreter.

\section{Composite Types}

The implementation of composite types (structs) requires the handling of three main concerns:

\begin{enumerate}
    \singlespacing
    \item The definition of structs and their members.
    \item The allocation of memory for a new instance of a struct.
    \item The referencing of struct members.
\end{enumerate}

Despite structs sharing the same two concerns as enums, the implementation detail is quite different
from that of enums, as the former requires the generation of a new type and the allocation of memory
for the struct in the LLVM IR\@. The following program demonstrates the use of structs:

\begin{tcolorbox}
    \begin{minted}{scala}
        struct Point = {
            x: Int,
            y: Int
        };

        def main() = {
            val p: Point = Point(1, 2);
            print(p.x + p.y);
            0
        }
        // Output: 3
    \end{minted}
    \tcblower
    \footnotesize
    An example program that demonstrates the use of structs.
    This example will be used throughout this section to illustrate the changes required.
\end{tcolorbox}

After the ANF IR generation, the struct definition is enclosed within the let-expression
encompassing the entire program. As with function definitions, the struct definition is hoisted out
into the top-level of the program.

Structs in the LLVM IR are represented as a series of elements, with each element being a member of
the struct. These elements do not have names as in the source language, but are instead accessed by
their index. It is therefore important to keep track of the order of elements in the struct
definition throughout generation. The struct definition is then emitted as a new type in the LLVM
IR\@, like so:

\begin{tcolorbox}[sidebyside]
    \begin{minted}{scala}
        // Program
        struct Point = {x: Int, y: Int};
    \end{minted}
    \tcblower
    \begin{minted}{llvm}
        ; LLVM IR
        %Point = type { i32, i32 }
    \end{minted}
\end{tcolorbox}

When creating a new instance of a struct, memory must be allocated for it. Memory allocation in the
LLVM IR can either be done on the stack or the heap. Allocating to the stack provides a simpler and
efficient solution, as the memory is automatically deallocated when a function returns. However,
this raises implications for the lifetime of the struct, as it is only valid within a narrow scope
as determined by the stack. Allocating to the heap (e.g. \texttt{malloc} in C) provides a more
flexible solution, as the memory is valid for the lifetime of the program, but requires either
explicit manual deallocation or the creation of a garbage collector.

For the purposes of this project, memory allocation is done on the stack using the \texttt{alloca}
instruction in the LLVM IR, returning a pointer to the allocated memory. For each element in the
struct to be allocated, a \texttt{getelementptr} instruction is used to calculate the address of the
element within the struct via its index, and a \texttt{store} instruction is used to store the value
of the element. The following is the LLVM IR for the creation of a new instance of the
\texttt{Point} struct:

\begin{tcolorbox}
    \begin{minted}{scala}
        // Program
        val p: Point = Point(1, 2);
    \end{minted}
    \tcblower
    \begin{minted}{llvm}
        ; LLVM IR
        %p = alloca %Point
        %tmp0 = getelementptr %Point, %Point* %p, i32 0, i32 0
        store i32 1, i32* %tmp0
        %tmp1 = getelementptr %Point, %Point* %p, i32 0, i32 1
        store i32 2, i32* %tmp1
    \end{minted}
\end{tcolorbox}

The referencing of struct members is done by using the \texttt{getelementptr} instruction to
calculate the address of the struct member via its index, and the \texttt{load} instruction to load
the value of the member into a local variable. To access the \texttt{x} and \texttt{y} members of
the \texttt{Point} struct, the following LLVM IR is generated:

\begin{tcolorbox}
    \begin{minted}{scala}
        // Program
        p.x + p.y
    \end{minted}
    \tcblower
    \begin{minted}{llvm}
        ; LLVM IR
        %tmp2 = getelementptr %Point, %Point* %p, i32 0, i32 0
        %tmp3 = load i32, i32* %tmp2
        %tmp4 = getelementptr %Point, %Point* %p, i32 0, i32 1
        %tmp5 = load i32, i32* %tmp4
        %tmp6 = add i32 %tmp3, %tmp5
    \end{minted}
\end{tcolorbox}

\section{Closures and Higher-order functions}

As mentioned in Chapter~\ref{ch:design}, there are three steps to implementing closures and
higher-order functions:

\begin{enumerate}
    \singlespacing
    \item Identifying free variables.
    \item Performing closure conversion.
    \item Hoisting the closure to the top-level.
\end{enumerate}

The following program demonstrates the use of closures and higher-order functions:

\begin{tcolorbox}
    \begin{minted}{scala}
    def foo(x: Int): (Int) => Int = {
        def bar(y: Int): Int = x + y;
        bar
    };

    def main() = {
      val add: (Int) => Int = foo(9);
      print(add(10));
      0
    }
    // Output: 19
    \end{minted}
    \tcblower
    \footnotesize
    An example program that demonstrates the use of closures and higher-order functions.
    This example will be used throughout this section to illustrate the changes required.
\end{tcolorbox}

The general idea is to convert the function into a closure, which will be a LLVM structure type
containing the free variables of the closure. The closure will then be rewritten to access the
environment for these variables. For example, the function definition
\mintinline{scala}{bar(y: Int): Int}
in the example above will convert to
\mintinline{scala}{bar(env: BarEnv, y: Int): Int}.

For identifying free variables within a function the ANF IR is traversed, while collecting all
variables that are not defined within the function itself. This is done by maintaining a set of
variables that are defined within the function, and adding any variable that is referenced but not
defined to the set of free variables. For instance, the function \texttt{bar} in the example above
contains free variable \texttt{x}. A series of recursive functions are used to achieve this:

\begin{code}{scala}
    def free_anf(e: KAnf): Set[KVar] = e match {
        case KFun(fnName, args, _, body, in) =>
            (free_anf(body) ++ free_anf(in))
                .filterNot(x => args.map(_._1).contains(x.s) || x.s == fnName)
        case KLet(x, e1, e2) => (free_exp(e1) ++ free_anf(e2)).filterNot(_.s == x)
        case KConst(x, v, e) => free_val(v) ++ free_anf(e)
        case KIf(x, e1, e2) => free_anf(e1) ++ free_anf(e2)
        // ... Other recurisve cases ...
    }

    def free_exp(e: KExp): Set[KVar] = e match {
        case Kop(o, v1, v2) => free_val(v1) ++ free_val(v2)
        case KStructDec(struct, vals) => vals.flatMap(free_val).toSet
        case KCall(o, vrs) => vrs.flatMap(free_val).toSet
    }

    def free_val(v: KVal): Set[KVar] = v match {
        case k: KVar => Set(k)
        case _ => Set()
    }
\end{code}

Once the free variables have been identified, the environment is created to store these
variables. A fresh global name is alloceted to it to avoid any naming collisions.
Included in the environment is a pointer to the function, allowing the function to be passed around
as a first-class object:
\mintinline{scala}{BarEnv = [Ptr, Int]}.
This environment is effectively the closure, as it contains all the information needed for the
function to be `closed' over. Note that for each new closure, a new environment type is needed, as
the free variables may differ between closures.

The function body is then rewritten to access the environment for these variables. By passing the
environment in as the first argument, the function can index into the corresponding field where a
free variable would be referenced. The final return statement of the function is also modified to
return the closure instead of the function itself. As an example, The function \texttt{bar} in the
example above is rewritten to access the environment for the variable \texttt{x}:

\begin{tcolorbox}
    \begin{minted}{scala}
        def foo(x: Int): (Int) => Int = {
            def bar(env: BarEnv, y: Int): Int = env[1] + y;
            bar // This is now type of BarEnv, not a function.
        };
    \end{minted}
    \tcblower
    \footnotesize
    For illustration purposes, this code is a representation of the changes that would be made
    to the ANF IR. This is not valid code in the project's current implementation of this language.
\end{tcolorbox}

Note that the return type of \texttt{foo} is now incorrect! It should be returning the closure
\mintinline{scala}{BarEnv} instead of a function \mintinline{scala}{(Int) => Int}. This is resolved
by traversing the ANF IR again and rectifying all references to the function to instead reference
the closure.

\begin{code}{scala}
    def convert(e: KAnf): (KAnf, Option[Env]) = e match {
        case KFun(fnName, args, ret, body, in) => {
            // Collect free variables
            val fvs = free_anf(body)
                .filterNot(x => args.map(_._1).contains(x.s)).toList
            ...
            // Create environment
            val envId = counter.Fresh("env")
            val newArgs = (envId, EnvType(envId)) +: args
            val newRet = if next_env.isEmpty then ret else EnvType(next_env.get.name)
            val newType = FnType(newArgs.map(_._2), newRet)
            val env = Env(envId, KVar(fnName, newType) :: fvs)

            // For each free variable, reference it from environment
            val (body2, _) = fvs.zipWithIndex.foldLeft(converted_body, 1) {
                    // LET x = env[i] IN anf
                    case ((next, i), (ssaVar, _)) =>
                        (KLetEnvRef(ssaVar.s, Ref(KVar(envId, EnvType(envId)), i), next), i + 1)
                }

            val (in2, _) = convert(in)
            // LET fn = (@fn, fvs...) IN anf
            val let_env = KLetEnv(fnName, env, in2)

            // Propagate the new type through the program
            val updated_body = update_types(body2, Map(fnName -> newType))
            val updated_in = update_types(let_env, Map(fnName -> newType))
            (KFun(fnName, newArgs, newRet, updated_body, updated_in), Some(env))
        }
    // ... Other cases ...
    }
\end{code}

For function calls that are now calling a closure, the function pointer within the environment must
be dereferenced before the function can be called. As the environment is constructed by placing the
function pointer as the first element, the function pointer can be accessed by indexing into the
environment with the integer 0. The function call is then rewritten to use the function pointer.
For example, the call to \texttt{add} in the example above is rewritten to access the function
pointer from the closure:

\begin{tcolorbox}
    \begin{minted}{scala}
        def main() = {
            val add: BarEnv = foo(9);
            print(add[0](10));
            0
        };
    \end{minted}
    \tcblower
    \footnotesize
    For illustration purposes, this code is a representation of the changes that would be made
    to the ANF IR. This is not valid code in the project's current implementation of this language.
\end{tcolorbox}

After closure conversion is complete and all relevant functions are closed, nested functions can be
safely hoisted to the top-level of the program. This is done similarly to the hoisting of
function and struct definitions. At this point, the closures are in a form that can be directly
translated to LLVM IR.

For lowering closures to LLVM IR, a structure type is created for each environment hoisted to the
top-level. In the case of the \mintinline{scala}{BarEnv} environment, the LLVM IR would be:

\begin{tcolorbox}
    \begin{minted}{llvm}
        ; LLVM IR
        %env_bar = type { i32 (%env_bar*, i32)*, i32 }
    \end{minted}
    \tcblower
    \footnotesize
    The first type, \mintinline{llvm}{i32 (%env_bar*, i32)*}, is a function pointer that takes a
    pointer to the environment and a 32-bit integer (\mintinline{llvm}{i32}) as arguments, returning
    an \mintinline{llvm}{i32} (i.e., the function \texttt{bar}). The second type,
    \mintinline{llvm}{i32}, is the free variable \texttt{x} in the closure.
\end{tcolorbox}

When creating a new instance of a closure, memory must be allocated for it. This is performed
similarly to the allocation of structs, where stack memory is allocated using the \texttt{alloca}
instruction in the LLVM IR, returning a pointer to the allocated memory. For each element in the
closure to be allocated, a \texttt{getelementptr} instruction is used to calculate the address of
the element within the closure via its index, and a \texttt{store} instruction is used to store the
value of the element. As the function was hoisted to the top-level, it is globally accessible in the
LLVM IR, and so can be added into the closure by name directly.

When calling a closure, \texttt{getelementptr} is used to locate the function pointer within the
closure, and the function is then called using the \texttt{call} instruction after dereferencing the
function pointer with \texttt{load}.

Finally, when accessing the free variables within the closure, \texttt{getelementptr} is used to
locate the appropriate field within the closure via its index, and \texttt{load} is used to load the
value of the free variable into a local variable.

The program example provided at the beginning of this section would be translated to the following
LLVM IR, after closure conversion:

\begin{code}{llvm}
    %env_bar = type { i32 (%env_bar*, i32)*, i32 }

    define %env_bar* @foo (i32 %x) {
        %bar = alloca %env_bar
        %bar0 = getelementptr %env_bar, %env_bar* %bar, i32 0, i32 0
        store i32 (%env_bar*, i32)* @bar, i32 (%env_bar*, i32)** %bar0
        %bar1 = getelementptr %env_bar, %env_bar* %bar, i32 0, i32 1
        store i32 %x, i32* %bar1
        ret %env_bar* %bar
    }

    define i32 @bar (%env_bar* %env, i32 %y) {
        %tmp_3 = getelementptr %env_bar, %env_bar* %env, i32 0, i32 1
        %x = load i32, i32* %tmp_3
        %tmp_4 = add i32 %x, %y
        ret i32 %tmp_4
    }

    define i32 @main () {
        %add = call %env_bar* @foo(i32 9)
        %tmp_0 = getelementptr %env_bar, %env_bar* %add, i32 0, i32 0
        %tmp_1 = load i32 (%env_bar*, i32)*, i32 (%env_bar*, i32)** %tmp_1
        %tmp_2 = call i32 %tmp_2(%env_bar* %add, i32 10)
        call void @print_i32(i32 %tmp_2)
        ret i32 0
    }
\end{code}
